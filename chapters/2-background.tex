\chapter{Background}

%5 pages minimum!, hopefully 8-10 though doubt it

%Section 1 on neural networks and how they work, CNNs, Alexnet, Inception (but no further)
\section{Neural networks}

%General theory for what a neural network is
%Small figure showing what it looks like (simple neuron image thing)

\subsection{History}

%Rundown on nn history, 4 paragraphs
%p1: 70s-90s
%p2: 90s-alexnet
%p3: alexnet, illustration of alexnet
%p4: googlenet

\subsection{Convolutional neural networks}

%Rundown on what a CNN is, what it is used for
%Subsections for the direct explanation on the layers

%S0: dense layers, basic
\subsubsection{Dense layer}

%S1: conv layer (in particular the 1D version)
\subsubsection{Convolutional layer}

%S2: pooling layers, max and average
\subsubsection{Pooling layer}

%Custom images for all of this, but based on theory

%One more subsection tied to optimizers, loss functions and other stuff?
%Working title Gradient descent, uncertain if correct
\subsection{Gradient descent}
%Network needs to be trained to work, the process of adjusting this is (title of part)

\subsubsection{Optimizers}
%RMSProp, Adam (and variants), SGD?

\subsubsection{Loss functions}
%Categorical crossentropy

\subsubsection{Metrics}
%Loss number, accuracy

%Section 2 on trees, current existing methods of grouping data (agg, k-means etc)

%Section 3 on how both tie together somewhat, use Tree-CNN as base and work up the chain in references

%Section 4 on iterative training, use Tree-CNN paper here too?

%Section 5 (probably earlier) on audio sample processing, what mfcc is, librosa